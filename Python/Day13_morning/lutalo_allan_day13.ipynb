{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Load the data set\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "# Define the target and features\n",
    "target = 'target'\n",
    "features = df.columns.tolist()\n",
    "features.remove(target)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8688524590163934\n"
     ]
    }
   ],
   "source": [
    "# Data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy:  0.81828231292517\n"
     ]
    }
   ],
   "source": [
    "# Cross validation\n",
    "model = RandomForestClassifier()\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Cross Validation Accuracy: \", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Evaluating the model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Test score accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Accuracy of the algorithms\n",
    "\n",
    "# initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=10000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_models(X_train, X_test, y_train, y_test, models):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results[name] = accuracy\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING AND TESTING SPLIT\n",
    "_Purpose_\n",
    "The primary purpose of splitting the dataset into training and testing sets is to evaluate the model's performance on unseen data. This helps in understanding how well the model generalizes to new data.\n",
    "\n",
    "_How it works_\n",
    "1.Training Set: A portion of the dataset used to train the model. The model learns the underlying patterns and relationships from this data.\n",
    "\n",
    "2.Testing Set: A separate portion of the dataset used to evaluate the model's performance. This data is not seen by the model during training, providing an unbiased assessment of its generalization capability.\n",
    "\n",
    "_Typical split ratio_\n",
    "A common split ratio is 70% for training and 30% for testing. Other popular ratios include 80/20 and 75/25.\n",
    "The choice of ratio can depend on the size of the dataset. For very large datasets, even a small percentage can provide a substantial test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing Split Results: {'Logistic Regression': 0.8131868131868132, 'Decision Tree': 0.7362637362637363, 'Random Forest': 0.8241758241758241, 'KNN': 0.6593406593406593, 'SVM': 0.7032967032967034}\n"
     ]
    }
   ],
   "source": [
    "# 1. Training and Testing Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "train_test_results = evaluate_models(X_train, X_test, y_train, y_test, models)\n",
    "print(\"Training and Testing Split Results:\", train_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VALIDATION\n",
    "_Purpose_:\n",
    "Cross-validation is used to assess the generalizability of a model. Instead of splitting the dataset into a single training set and a single test set, cross-validation divides the dataset into multiple folds, trains the model on some folds, and tests it on the remaining fold. This process is repeated several times, and the results are averaged to provide a more reliable estimate of model performance.\n",
    "\n",
    "_How it works_\n",
    "1.The dataset is divided into k subsets (folds).\n",
    "2.The model is trained on k-1 folds and tested on the remaining fold.\n",
    "3.This process is repeated k times, with each fold used exactly once as the test set.\n",
    "4.The performance metrics (e.g., accuracy, precision, recall) are averaged over all k runs to get a final evaluation score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results: {'Logistic Regression': 0.8282513661202187, 'Decision Tree': 0.755464480874317, 'Random Forest': 0.8381967213114756, 'KNN': 0.643879781420765, 'SVM': 0.6434972677595628}\n"
     ]
    }
   ],
   "source": [
    "# 2. Cross-Validation\n",
    "cross_val_results = {}\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=5)\n",
    "    cross_val_results[name] = scores.mean()\n",
    "print(\"Cross-Validation Results:\", cross_val_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRATIFIED SPLITTING / STRATIFIED CROSS VALIDATION\n",
    "_Purpose_:\n",
    "Stratified splitting ensures that each fold of the dataset maintains the same proportion of classes as the original dataset. This is particularly important for classification problems where the class distribution is imbalanced.\n",
    "\n",
    "_How it works_\n",
    "The dataset is divided into k folds in such a way that each fold has approximately the same percentage of samples of each target class as the original dataset.\n",
    "The model is trained and validated using these stratified folds.\n",
    "\n",
    "Note: Imbalanced Dataset;\n",
    "      is a dataset where the distribution of classes is not uniform. In other words, one class significantly outnumbers the other class(es).\n",
    "      e.g:Medical Diagnosis: In medical datasets, the number of patients with a rare disease (positive class) is often much smaller than the number of healthy patients (negative class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified Cross-Validation Results: {'Logistic Regression': 0.8282513661202187, 'Decision Tree': 0.755464480874317, 'Random Forest': 0.8381967213114756, 'KNN': 0.643879781420765, 'SVM': 0.6434972677595628}\n"
     ]
    }
   ],
   "source": [
    "# 3. Stratified Splitting\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "stratified_results = {}\n",
    "for name, model in models.items():\n",
    "    accuracies = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    stratified_results[name] = np.mean(accuracies)\n",
    "print(\"Stratified Cross-Validation Results:\", stratified_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the metrics\n",
    "metrics = {\n",
    "    'Accuracy': accuracy_score,\n",
    "    'Precision': precision_score,\n",
    "    'Recall': recall_score,\n",
    "    'F1_score': f1_score,\n",
    "    'ROC AUC': roc_auc_score\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"_summary_\n",
    "steps:\n",
    "1.Train the Models: Fit each model to the training data.\n",
    "2.Predict on Test Data: Use the trained model to predict the target variable for the test data.\n",
    "3.Calculate Metrics: Calculate the performance metrics using the true and predicted values of the target variable.\n",
    "\"\"\"\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    model_results = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1_score': f1_score(y_test, y_pred),\n",
    "        'ROC AUC': roc_auc_score(y_test, y_prob) if y_prob is not None else 'N/A'\n",
    "    }\n",
    "    \n",
    "    # Store the results\n",
    "    results[name] = model_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Logistic Regression:\n",
      "  Accuracy: 0.8132\n",
      "  Precision: 0.8235\n",
      "  Recall: 0.8400\n",
      "  F1_score: 0.8317\n",
      "  ROC AUC: 0.8820\n",
      "\n",
      "Results for Decision Tree:\n",
      "  Accuracy: 0.7363\n",
      "  Precision: 0.7955\n",
      "  Recall: 0.7000\n",
      "  F1_score: 0.7447\n",
      "  ROC AUC: 0.7402\n",
      "\n",
      "Results for Random Forest:\n",
      "  Accuracy: 0.8242\n",
      "  Precision: 0.8400\n",
      "  Recall: 0.8400\n",
      "  F1_score: 0.8400\n",
      "  ROC AUC: 0.9095\n",
      "\n",
      "Results for KNN:\n",
      "  Accuracy: 0.6593\n",
      "  Precision: 0.6792\n",
      "  Recall: 0.7200\n",
      "  F1_score: 0.6990\n",
      "  ROC AUC: 0.7132\n",
      "\n",
      "Results for SVM:\n",
      "  Accuracy: 0.7033\n",
      "  Precision: 0.6716\n",
      "  Recall: 0.9000\n",
      "  F1_score: 0.7692\n",
      "  ROC AUC: 0.7946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_results in results.items():\n",
    "    print(f\"Results for {model_name}:\")\n",
    "    for metric_name, value in model_results.items():\n",
    "        print(f\"  {metric_name}: {value:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actionable insight of the models\n",
    "# LR\n",
    "# Best performed model : Logistic Regression\n",
    "# Precision (0.08), Recall (0.90), f1_score (0.89), ROC AUC (0.91)\n",
    "\n",
    "# Balance model performance:\n",
    "#\n",
    "# KNN\n",
    "\n",
    "# SVM\n",
    "\n",
    "# DT\n",
    "\n",
    "# RF\n",
    "\n",
    "# Conclusion\n",
    "# Logistic regression is the best performer model with the higest core metrics\n",
    "\n",
    "#\n",
    "\n",
    "# Recommendation\n",
    "# Models considered for deployment\n",
    "\n",
    "# Furtur funing of the models\n",
    "\n",
    "# Ensemble methods, enhancing performance nd robustness "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
